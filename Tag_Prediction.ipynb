{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np \n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "from itertools import chain\n",
    "\n",
    "# Ignore warnings when training data due to empty tags predicted \n",
    "warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Reading Dataset\n",
    "data = pd.read_csv('export.csv')\n",
    "              \n",
    "# Function to clean text in data\n",
    "def clean_text(text):\n",
    "    \n",
    "    if not isinstance(text, str): \n",
    "        return text\n",
    "    text = re.sub('<pre><code>.*?</code></pre>', '', text)\n",
    "\n",
    "    def replace_link(match):\n",
    "        return '' if re.match('[a-z]+://', match.group(1)) else match.group(1)\n",
    "    \n",
    "    text = re.sub('<a[^>]+>(.*)</a>', replace_link, text)\n",
    "    return re.sub('<[^>]+>', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding higher weightage to Title \n",
    "Weightage = 5\n",
    "\n",
    "# Combining Title and Body while applying clean_text function to pre-process data\n",
    "data['Text'] = (data['Title'] + \" \")*Weightage + data['Body']\n",
    "data['Text'] = data['Text'].apply(clean_text).str.lower()\n",
    "data['Text'] = data.Text.apply(lambda x: x.replace('\"','').replace(\"\\n\",\"\").replace(\"\\t\",\"\"))\n",
    "\n",
    "# Apply split on Tags \n",
    "f = lambda x: x[\"Tags\"].split()\n",
    "data[\"Tags\"] = data.apply(f, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# Initialize variables\n",
    "totaltags = []\n",
    "toptags = []\n",
    "\n",
    "# Number of top tags used for the model\n",
    "n = 1000\n",
    "\n",
    "# Retrieve total tags for each row\n",
    "for i in range(data['Tags'].size):\n",
    "    totaltags.extend(data['Tags'][i])\n",
    "\n",
    "# Number of usages for the n of most repeated tags\n",
    "tagcount = collections.Counter(totaltags).most_common(n)\n",
    "\n",
    "# Append most used tags into array\n",
    "for i in range(len(tagcount)):\n",
    "    toptags.append(tagcount[i][0])\n",
    "toptags = np.array(toptags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split Data into 80% Train and 20% Test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Tags'], random_state=42, test_size=0.2, shuffle=True)\n",
    "\n",
    "# Apply multilabel binarizer for n top tags used\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit([toptags])\n",
    "y_initial = y_test\n",
    "\n",
    "# Transform y_train and y_test into binary form\n",
    "y_train = multilabel_binarizer.transform(y_train)\n",
    "y_test = multilabel_binarizer.transform(y_test)\n",
    "\n",
    "# OneVsRestClassifier with Logistic Regression\n",
    "classifier = OneVsRestClassifier(LogisticRegression(penalty='l1'))\n",
    "\n",
    "# TF-IDF approach \n",
    "vectorizer = TfidfVectorizer(min_df = 2, max_df = 0.95, stop_words='english', max_features=10000, smooth_idf=True, norm=\"l2\",sublinear_tf=False, ngram_range=(1,3))\n",
    "vectorizer.fit(X_train)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Fitting Train data into classifier\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "prediction = multilabel_binarizer.inverse_transform(y_pred)\n",
    "multilabel_binarizer.fit(data['Tags'])\n",
    "y_test_all = multilabel_binarizer.transform(y_initial)\n",
    "y_pred_all = multilabel_binarizer.transform(prediction)\n",
    "\n",
    "# Comparison table of predicted and actual values\n",
    "comp = pd.Series(y_initial).reset_index()\n",
    "comp2 = pd.Series(prediction)\n",
    "comparison = pd.concat([comp,comp2], axis = 1)\n",
    "\n",
    "# Micro f1 score\n",
    "precision = precision_score(y_test_all, y_pred_all, average = 'micro')\n",
    "recall = recall_score(y_test_all, y_pred_all, average = 'micro')\n",
    "f1 = f1_score(y_test_all, y_pred_all, average=\"micro\")\n",
    "print('Micro')\n",
    "print('Precision: {:.4f}\\nRecall: {:.4f}\\nF1: {:4f}'.format(precision, recall, f1))\n",
    "\n",
    "# Hamming loss score\n",
    "print(\"Hamming loss \",hamming_loss(y_test_all,y_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison Table for visualization purposes\n",
    "comparison.columns = ['Index', 'Actual Tags', 'Predicted Tags']\n",
    "comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
